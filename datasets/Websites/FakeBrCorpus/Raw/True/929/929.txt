Checava se alguém se mataria ao vivo: a rotina de um moderador brasileiro de posts denunciados no Facebook. Na semana em que Zuckerberg anuncia 10 mil novas contratações para moderação de conteúdos, ex-funcionário brasileiro narra desafios da rede contra a violência e jornadas aceleradas para garantir metas de uma revisão a cada 8,5 segundos. Grupo de amigos incendeia cachorro de rua com isqueiro. Adolescentes são forçados a fazer sexo oral mútuo em acerto de contas do tráfico. Menina com lâmina de barbear anuncia suicídio em vídeo ao vivo. Recém-nascido é espancado por parente no berço. Vaca é despedaçada viva em moedor gigante de madeira. Tudo o que há de pior no Facebook durante 8 horas diárias, de segunda a sexta-feira, em troca de um salário mínimo. O brasileiro Sergio, que pede para não ser identificado, viveu esta rotina por um ano, até abandonar o emprego de revisor de denúncias sobre violência e ódio em português na rede social - e se tornar uma pessoa mais "fria e insensível" na vida offline. "Eu via vídeos ao vivo para checar se alguém se mataria", diz ele, cuja função era decidir o mais rápido possível se publicações agressivas eram toleráveis ou passavam dos limites estabelecidos pelo Facebook. Em seu escritório, a meta para cada revisor era avaliar, por dia, 3.500 fotos, vídeos e textos denunciados. Mais de 7 por minuto, ou um a cada 8,5 segundos. "Impossível não ter erro humano nesse ritmo", diz Sergio, que hoje trabalha como freelancer e decidiu abandonar qualquer interação na rede social depois de a conhecer "por dentro". Na semana em que Mark Zuckerberg anunciou a contratação de 10 mil novos funcionários diretos e indiretos para funções como a desempenhada por Sergio, a rotina do brasileiro em uma espécie de "call center" digital ilustra o desafio enfrentado pelo Facebook para conter milhões de demonstrações explícitas de violência com consequências cada vez mais dramáticas - do incentivo a suicídios infantis a ameaças à segurança nacional do país mais rico do mundo. 

Esqueça as notícias falsas - os vídeos falsos estão chegando. Ferramentas de vídeo que usam inteligência artificial para sobrepor rostos são um novo risco na internet. A cena se abria e via-se um quarto com um sofá vermelho, uma planta em um vaso e arte moderna suave. Na sala estava Michelle Obama, ou uma mulher exatamente semelhante a ela. Usando um top com decote profundo e um sutiã preto visível por baixo, retorcia-se voluptuosamente para a câmera, abrindo o seu sorriso inconfundível. Então, a sósia da ex-primeira dama começava a tirar a roupa. O vídeo que apareceu no fórum online Reddit era o que conhecemos como um “deepfake” -um vídeo falso extremamente realista feito com software da inteligência artificial. Foi criado usando um programa chamado FakeApp, que sobrepôs o rosto de Michelle Obama ao corpo de uma atriz de filmes pornográficos. O híbrido era extraordinário - se você não fosse uma pessoa informada, pensaria que era realmente ela. Até pouco tempo atrás, um vídeo realista gerado por computador era uma façanha trabalhosa, disponível somente a produções hollywoodianas de grande orçamento ou a pesquisadores de ponta. Os aplicativos de redes sociais como Snapchat incluem uma tecnologia rudimentar de transformação do rosto. Mas nos últimos meses, uma comunidade de amadores começou a experimentar com ferramentas mais potentes, como o FakeApp - um programa criado por um anônimo desenvolvedor que usou um programa de código aberto escrito pelo Google. O FakeApp permite gratuitamente e de maneira relativamente fácil mudar o rosto, deixando poucos sinais de manipulação. Desde que uma versão do aplicativo apareceu no Reddit em janeiro, foi baixada mais de 120 mil vezes, segundo seu criador. Os deepfakes são uma das formas mais novas de manipulação da mídia digital, e uma das obviamente mais fáceis de serem usadas para cometer maldades. Não é difícil imaginar que esta tecnologia está sendo usada para manchar a reputação de políticos, criar falsa pornografia por vingança ou armar para uma pessoa a fim de acusá-la de crimes. Os legisladores já começam a temer que estes deepfakes possam ser 
